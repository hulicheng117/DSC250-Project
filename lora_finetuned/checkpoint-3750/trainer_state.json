{
  "best_metric": 0.05835038051009178,
  "best_model_checkpoint": "./lora_finetuned\\checkpoint-3750",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 3750,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04,
      "grad_norm": 0.21485276520252228,
      "learning_rate": 0.0009882666666666665,
      "loss": 4.776,
      "step": 50
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5499794483184814,
      "learning_rate": 0.0009749333333333334,
      "loss": 0.1465,
      "step": 100
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.12719985842704773,
      "learning_rate": 0.0009616000000000001,
      "loss": 0.1136,
      "step": 150
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.10436920076608658,
      "learning_rate": 0.0009482666666666668,
      "loss": 0.0889,
      "step": 200
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.12780967354774475,
      "learning_rate": 0.0009349333333333333,
      "loss": 0.0748,
      "step": 250
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.48650234937667847,
      "learning_rate": 0.0009216,
      "loss": 0.0875,
      "step": 300
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.0960949957370758,
      "learning_rate": 0.0009082666666666667,
      "loss": 0.0765,
      "step": 350
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.17584748566150665,
      "learning_rate": 0.0008949333333333334,
      "loss": 0.0832,
      "step": 400
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.1090078130364418,
      "learning_rate": 0.0008816000000000001,
      "loss": 0.0681,
      "step": 450
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.13524512946605682,
      "learning_rate": 0.0008685333333333334,
      "loss": 0.0753,
      "step": 500
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.08660203218460083,
      "learning_rate": 0.0008552,
      "loss": 0.0688,
      "step": 550
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.599318265914917,
      "learning_rate": 0.0008418666666666667,
      "loss": 0.0592,
      "step": 600
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.14266745746135712,
      "learning_rate": 0.0008285333333333334,
      "loss": 0.0766,
      "step": 650
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.14934182167053223,
      "learning_rate": 0.0008152000000000001,
      "loss": 0.0824,
      "step": 700
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.06758145242929459,
      "learning_rate": 0.0008018666666666667,
      "loss": 0.0578,
      "step": 750
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.06279922276735306,
      "learning_rate": 0.0007885333333333333,
      "loss": 0.0684,
      "step": 800
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.16276012361049652,
      "learning_rate": 0.0007752,
      "loss": 0.0798,
      "step": 850
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.166425421833992,
      "learning_rate": 0.0007618666666666667,
      "loss": 0.059,
      "step": 900
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.11692668497562408,
      "learning_rate": 0.0007485333333333334,
      "loss": 0.0702,
      "step": 950
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.10852047055959702,
      "learning_rate": 0.0007352,
      "loss": 0.0698,
      "step": 1000
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.14859050512313843,
      "learning_rate": 0.0007218666666666667,
      "loss": 0.0554,
      "step": 1050
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.19935822486877441,
      "learning_rate": 0.0007085333333333334,
      "loss": 0.0573,
      "step": 1100
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.07752837985754013,
      "learning_rate": 0.0006952000000000001,
      "loss": 0.0703,
      "step": 1150
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.06709402054548264,
      "learning_rate": 0.0006818666666666667,
      "loss": 0.0678,
      "step": 1200
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.09230101108551025,
      "learning_rate": 0.0006685333333333333,
      "loss": 0.0633,
      "step": 1250
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.06727290153503418,
      "eval_runtime": 13.4547,
      "eval_samples_per_second": 148.647,
      "eval_steps_per_second": 18.581,
      "step": 1250
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.08525172621011734,
      "learning_rate": 0.0006552,
      "loss": 0.0556,
      "step": 1300
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.07946251332759857,
      "learning_rate": 0.0006418666666666667,
      "loss": 0.0653,
      "step": 1350
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.05406767874956131,
      "learning_rate": 0.0006285333333333334,
      "loss": 0.0725,
      "step": 1400
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.20960448682308197,
      "learning_rate": 0.0006152,
      "loss": 0.0603,
      "step": 1450
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.20440155267715454,
      "learning_rate": 0.0006018666666666667,
      "loss": 0.0596,
      "step": 1500
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.07162351906299591,
      "learning_rate": 0.0005885333333333334,
      "loss": 0.0642,
      "step": 1550
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.12009955197572708,
      "learning_rate": 0.0005752000000000001,
      "loss": 0.0553,
      "step": 1600
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.18138130009174347,
      "learning_rate": 0.0005618666666666666,
      "loss": 0.0633,
      "step": 1650
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.11858458071947098,
      "learning_rate": 0.0005485333333333333,
      "loss": 0.0609,
      "step": 1700
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.1717080920934677,
      "learning_rate": 0.0005354666666666667,
      "loss": 0.0599,
      "step": 1750
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.1190488189458847,
      "learning_rate": 0.0005224,
      "loss": 0.0641,
      "step": 1800
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.14185620844364166,
      "learning_rate": 0.0005090666666666667,
      "loss": 0.0532,
      "step": 1850
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.05259623005986214,
      "learning_rate": 0.0004957333333333334,
      "loss": 0.0524,
      "step": 1900
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.12073638290166855,
      "learning_rate": 0.0004824,
      "loss": 0.0607,
      "step": 1950
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.05347796902060509,
      "learning_rate": 0.0004690666666666667,
      "loss": 0.0605,
      "step": 2000
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.784466028213501,
      "learning_rate": 0.0004557333333333333,
      "loss": 0.0582,
      "step": 2050
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.15414047241210938,
      "learning_rate": 0.0004424,
      "loss": 0.0641,
      "step": 2100
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.10997923463582993,
      "learning_rate": 0.00042906666666666667,
      "loss": 0.0517,
      "step": 2150
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.10428155958652496,
      "learning_rate": 0.0004157333333333334,
      "loss": 0.0492,
      "step": 2200
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.04737377166748047,
      "learning_rate": 0.00040239999999999997,
      "loss": 0.0488,
      "step": 2250
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.14686910808086395,
      "learning_rate": 0.0003890666666666667,
      "loss": 0.0574,
      "step": 2300
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.0692303404211998,
      "learning_rate": 0.0003757333333333333,
      "loss": 0.0591,
      "step": 2350
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.05243068188428879,
      "learning_rate": 0.0003624,
      "loss": 0.0609,
      "step": 2400
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.1368326097726822,
      "learning_rate": 0.0003490666666666667,
      "loss": 0.0619,
      "step": 2450
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.0450277253985405,
      "learning_rate": 0.0003357333333333333,
      "loss": 0.0573,
      "step": 2500
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.06180771440267563,
      "eval_runtime": 13.3332,
      "eval_samples_per_second": 150.002,
      "eval_steps_per_second": 18.75,
      "step": 2500
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.08059104532003403,
      "learning_rate": 0.00032240000000000003,
      "loss": 0.0483,
      "step": 2550
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.09328281134366989,
      "learning_rate": 0.0003090666666666667,
      "loss": 0.0597,
      "step": 2600
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.09583409130573273,
      "learning_rate": 0.00029573333333333333,
      "loss": 0.0527,
      "step": 2650
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.3367610573768616,
      "learning_rate": 0.0002824,
      "loss": 0.0557,
      "step": 2700
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.1274229884147644,
      "learning_rate": 0.0002690666666666667,
      "loss": 0.0535,
      "step": 2750
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.15642274916172028,
      "learning_rate": 0.00025573333333333333,
      "loss": 0.0576,
      "step": 2800
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.07105698436498642,
      "learning_rate": 0.0002424,
      "loss": 0.0587,
      "step": 2850
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.03639291226863861,
      "learning_rate": 0.00022906666666666666,
      "loss": 0.0654,
      "step": 2900
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.45523688197135925,
      "learning_rate": 0.00021573333333333334,
      "loss": 0.0477,
      "step": 2950
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.09906245023012161,
      "learning_rate": 0.00020240000000000001,
      "loss": 0.0513,
      "step": 3000
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.056431133300065994,
      "learning_rate": 0.00018906666666666666,
      "loss": 0.0515,
      "step": 3050
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.1402999311685562,
      "learning_rate": 0.00017573333333333334,
      "loss": 0.0514,
      "step": 3100
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.1671682447195053,
      "learning_rate": 0.0001624,
      "loss": 0.0496,
      "step": 3150
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.08468157052993774,
      "learning_rate": 0.00014906666666666667,
      "loss": 0.0456,
      "step": 3200
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.10003412514925003,
      "learning_rate": 0.00013573333333333334,
      "loss": 0.0402,
      "step": 3250
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.1218533143401146,
      "learning_rate": 0.0001224,
      "loss": 0.0597,
      "step": 3300
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.10241977125406265,
      "learning_rate": 0.00010906666666666667,
      "loss": 0.0457,
      "step": 3350
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.15359820425510406,
      "learning_rate": 9.573333333333333e-05,
      "loss": 0.0429,
      "step": 3400
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.10740301012992859,
      "learning_rate": 8.24e-05,
      "loss": 0.0497,
      "step": 3450
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.08242858946323395,
      "learning_rate": 6.906666666666666e-05,
      "loss": 0.0489,
      "step": 3500
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.04953712224960327,
      "learning_rate": 5.573333333333334e-05,
      "loss": 0.0538,
      "step": 3550
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.3572355806827545,
      "learning_rate": 4.24e-05,
      "loss": 0.0484,
      "step": 3600
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.17840887606143951,
      "learning_rate": 2.9066666666666667e-05,
      "loss": 0.0529,
      "step": 3650
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.07532886415719986,
      "learning_rate": 1.573333333333333e-05,
      "loss": 0.0493,
      "step": 3700
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.07863570749759674,
      "learning_rate": 2.4e-06,
      "loss": 0.0647,
      "step": 3750
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.05835038051009178,
      "eval_runtime": 13.8226,
      "eval_samples_per_second": 144.691,
      "eval_steps_per_second": 18.086,
      "step": 3750
    }
  ],
  "logging_steps": 50,
  "max_steps": 3750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4597760655360000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
