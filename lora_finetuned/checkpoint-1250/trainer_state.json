{
  "best_metric": 0.06727290153503418,
  "best_model_checkpoint": "./lora_finetuned\\checkpoint-1250",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1250,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04,
      "grad_norm": 0.21485276520252228,
      "learning_rate": 0.0009882666666666665,
      "loss": 4.776,
      "step": 50
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5499794483184814,
      "learning_rate": 0.0009749333333333334,
      "loss": 0.1465,
      "step": 100
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.12719985842704773,
      "learning_rate": 0.0009616000000000001,
      "loss": 0.1136,
      "step": 150
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.10436920076608658,
      "learning_rate": 0.0009482666666666668,
      "loss": 0.0889,
      "step": 200
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.12780967354774475,
      "learning_rate": 0.0009349333333333333,
      "loss": 0.0748,
      "step": 250
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.48650234937667847,
      "learning_rate": 0.0009216,
      "loss": 0.0875,
      "step": 300
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.0960949957370758,
      "learning_rate": 0.0009082666666666667,
      "loss": 0.0765,
      "step": 350
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.17584748566150665,
      "learning_rate": 0.0008949333333333334,
      "loss": 0.0832,
      "step": 400
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.1090078130364418,
      "learning_rate": 0.0008816000000000001,
      "loss": 0.0681,
      "step": 450
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.13524512946605682,
      "learning_rate": 0.0008685333333333334,
      "loss": 0.0753,
      "step": 500
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.08660203218460083,
      "learning_rate": 0.0008552,
      "loss": 0.0688,
      "step": 550
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.599318265914917,
      "learning_rate": 0.0008418666666666667,
      "loss": 0.0592,
      "step": 600
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.14266745746135712,
      "learning_rate": 0.0008285333333333334,
      "loss": 0.0766,
      "step": 650
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.14934182167053223,
      "learning_rate": 0.0008152000000000001,
      "loss": 0.0824,
      "step": 700
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.06758145242929459,
      "learning_rate": 0.0008018666666666667,
      "loss": 0.0578,
      "step": 750
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.06279922276735306,
      "learning_rate": 0.0007885333333333333,
      "loss": 0.0684,
      "step": 800
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.16276012361049652,
      "learning_rate": 0.0007752,
      "loss": 0.0798,
      "step": 850
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.166425421833992,
      "learning_rate": 0.0007618666666666667,
      "loss": 0.059,
      "step": 900
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.11692668497562408,
      "learning_rate": 0.0007485333333333334,
      "loss": 0.0702,
      "step": 950
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.10852047055959702,
      "learning_rate": 0.0007352,
      "loss": 0.0698,
      "step": 1000
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.14859050512313843,
      "learning_rate": 0.0007218666666666667,
      "loss": 0.0554,
      "step": 1050
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.19935822486877441,
      "learning_rate": 0.0007085333333333334,
      "loss": 0.0573,
      "step": 1100
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.07752837985754013,
      "learning_rate": 0.0006952000000000001,
      "loss": 0.0703,
      "step": 1150
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.06709402054548264,
      "learning_rate": 0.0006818666666666667,
      "loss": 0.0678,
      "step": 1200
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.09230101108551025,
      "learning_rate": 0.0006685333333333333,
      "loss": 0.0633,
      "step": 1250
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.06727290153503418,
      "eval_runtime": 13.4547,
      "eval_samples_per_second": 148.647,
      "eval_steps_per_second": 18.581,
      "step": 1250
    }
  ],
  "logging_steps": 50,
  "max_steps": 3750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1532586885120000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
